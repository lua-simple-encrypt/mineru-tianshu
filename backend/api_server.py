"""
MinerU Tianshu - API Server
å¤©æ¢ API æœåŠ¡å™¨

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°
æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
æä¾› RESTful API æ¥å£ç”¨äºä»»åŠ¡æäº¤ã€æŸ¥è¯¢å’Œç®¡ç†
ä¼ä¸šçº§è®¤è¯æˆæƒ: JWT Token + API Key + SSO
"""

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query, Depends
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
from loguru import logger
import uvicorn
from typing import Optional
from datetime import datetime
import os
import re
import uuid
from urllib.parse import quote
from minio import Minio

from task_db import TaskDB

# å¯¼å…¥è®¤è¯æ¨¡å—
from auth import (
    User,
    Permission,
    get_current_active_user,
    require_permission,
)
from auth.routes import router as auth_router
from auth.auth_db import AuthDB

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="MinerU Tianshu API",
    description="å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å° | æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç† | ä¼ä¸šçº§è®¤è¯æˆæƒ",
    version="2.0.0",
    # ä¸è®¾ç½® serversï¼Œè®© FastAPI è‡ªåŠ¨æ ¹æ®è¯·æ±‚çš„ Host ç”Ÿæˆ
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ•°æ®åº“
# ç¡®ä¿ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ•°æ®åº“è·¯å¾„ï¼ˆä¸ Worker ä¿æŒä¸€è‡´ï¼‰
db_path_env = os.getenv("DATABASE_PATH")
if db_path_env:
    db_path = str(Path(db_path_env).resolve())
    logger.info(f"ğŸ“Š API Server using DATABASE_PATH: {db_path_env} -> {db_path}")
    db = TaskDB(db_path)
else:
    logger.warning("âš ï¸  DATABASE_PATH not set in API Server, using default")
    # ä½¿ç”¨ä¸ Worker ä¸€è‡´çš„é»˜è®¤è·¯å¾„
    db_path = "/app/data/db/mineru_tianshu.db"
    db = TaskDB(db_path)
auth_db = AuthDB()

# æ³¨å†Œè®¤è¯è·¯ç”±
app.include_router(auth_router)

# é…ç½®è¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨å…±äº«ç›®å½•ï¼ŒDocker ç¯å¢ƒå¯è®¿é—®ï¼‰
OUTPUT_DIR = Path(os.getenv("OUTPUT_PATH", "/app/output"))
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# MinIO é…ç½®
MINIO_CONFIG = {
    "endpoint": os.getenv("MINIO_ENDPOINT", ""),
    "access_key": os.getenv("MINIO_ACCESS_KEY", ""),
    "secret_key": os.getenv("MINIO_SECRET_KEY", ""),
    "secure": True,
    "bucket_name": os.getenv("MINIO_BUCKET", ""),
}


def get_minio_client():
    """è·å–MinIOå®¢æˆ·ç«¯å®ä¾‹"""
    return Minio(
        MINIO_CONFIG["endpoint"],
        access_key=MINIO_CONFIG["access_key"],
        secret_key=MINIO_CONFIG["secret_key"],
        secure=MINIO_CONFIG["secure"],
    )


def process_markdown_images(md_content: str, image_dir: Path, result_path: str, upload_images: bool = False):
    """
    å¤„ç† Markdown ä¸­çš„å›¾ç‰‡å¼•ç”¨

    å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºå¯è®¿é—®çš„ URLï¼ˆé™æ€æ–‡ä»¶æœåŠ¡æˆ– MinIOï¼‰
    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. Markdown è¯­æ³•ï¼š![alt](path)
    2. HTML æ ‡ç­¾ï¼š<img src="path" ...>

    Args:
        md_content: Markdown å†…å®¹
        image_dir: å›¾ç‰‡æ‰€åœ¨ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼ŒWorker å·²è§„èŒƒåŒ–ä¸º images/ï¼‰
        result_path: ä»»åŠ¡ç»“æœè·¯å¾„ï¼ˆä»æ•°æ®åº“è·å–ï¼Œä¾‹å¦‚: /app/output/{file_stem}ï¼‰
        upload_images: æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢é“¾æ¥

    Returns:
        å¤„ç†åçš„ Markdown å†…å®¹
    """

    def process_image_path(image_path: str, alt_text: str = "Image") -> tuple[str, str]:
        """
        å¤„ç†å›¾ç‰‡è·¯å¾„ï¼Œè¿”å› (æ–°è·¯å¾„, æ ¼å¼ç±»å‹)

        Returns:
            (new_url, format_type)  format_type: 'markdown' æˆ– 'html'
        """
        # æå–å›¾ç‰‡æ–‡ä»¶å
        image_filename = Path(image_path).name

        # æ„å»ºå®Œæ•´çš„æœ¬åœ°å›¾ç‰‡è·¯å¾„
        full_image_path = image_dir / image_filename

        logger.debug(f"ğŸ” Processing image: {image_path} -> {full_image_path}")

        if not full_image_path.exists():
            logger.warning(f"âš ï¸  Image not found: {full_image_path}")
            return None, None

        # å¦‚æœéœ€è¦ä¸Šä¼ åˆ° MinIO
        if upload_images:
            try:
                minio_client = get_minio_client()
                bucket_name = MINIO_CONFIG["bucket_name"]
                minio_endpoint = MINIO_CONFIG["endpoint"]

                # è·å–æ–‡ä»¶åç¼€
                file_extension = full_image_path.suffix
                # ç”Ÿæˆ UUID ä½œä¸ºæ–°æ–‡ä»¶å
                new_filename = f"{uuid.uuid4()}{file_extension}"

                # ä¸Šä¼ åˆ° MinIO
                object_name = f"images/{new_filename}"
                minio_client.fput_object(bucket_name, object_name, str(full_image_path))

                # ç”Ÿæˆ MinIO è®¿é—® URL
                scheme = "https" if MINIO_CONFIG["secure"] else "http"
                minio_url = f"{scheme}://{minio_endpoint}/{bucket_name}/{object_name}"

                logger.info(f"âœ… Uploaded to MinIO: {object_name}")
                return minio_url, "html"
            except Exception as e:
                logger.error(f"âŒ Failed to upload image to MinIO: {e}")
                # ä¸Šä¼ å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æœ¬åœ°é™æ€æ–‡ä»¶æœåŠ¡

        # ä½¿ç”¨æœ¬åœ°é™æ€æ–‡ä»¶æœåŠ¡
        # result_path æ ¼å¼: /app/output/{file_stem}
        # Worker å·²è§„èŒƒåŒ–å›¾ç‰‡ç›®å½•ä¸º: images/
        # éœ€è¦è½¬æ¢ä¸º: /api/v1/files/output/{file_stem}/images/xxx.jpg
        try:
            # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²æ›¿æ¢ï¼Œé¿å… Path å¯¹è±¡çš„ç¼–ç é—®é¢˜
            output_dir_str = str(OUTPUT_DIR).replace("\\", "/")  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
            result_path_str = result_path.replace("\\", "/")

            if result_path_str.startswith(output_dir_str):
                # æå–ç›¸å¯¹è·¯å¾„
                relative_path = result_path_str[len(output_dir_str) :].lstrip("/")
                # å¯¹è·¯å¾„è¿›è¡Œ URL ç¼–ç ï¼ˆsafe='/' ä¿ç•™æ–œæ ï¼‰
                encoded_relative_path = quote(relative_path, safe="/")
                # å¯¹å›¾ç‰‡æ–‡ä»¶åè¿›è¡Œ URL ç¼–ç 
                encoded_image_filename = quote(image_filename, safe="/")
                # æ„å»º API æ–‡ä»¶è®¿é—® URLï¼ˆå›¾ç‰‡ç›®å½•å·²è§„èŒƒåŒ–ä¸º images/ï¼‰
                static_url = f"/api/v1/files/output/{encoded_relative_path}/images/{encoded_image_filename}"
            else:
                # å¦‚æœè·¯å¾„ä¸åŒ¹é…ï¼Œå°è¯•ç›´æ¥æ‹¼æ¥
                logger.warning(f"âš ï¸  result_path doesn't start with OUTPUT_DIR: {result_path}")
                encoded_image_filename = quote(image_filename, safe="/")
                static_url = f"/api/v1/files/output/images/{encoded_image_filename}"

            logger.debug(f"ğŸ“¸ Image URL: {static_url}")
            return static_url, "markdown"
        except Exception as e:
            logger.error(f"âŒ Failed to generate static URL: {e}")
            return None, None

    # 1. å¤„ç† Markdown æ ¼å¼çš„å›¾ç‰‡ï¼š![alt](path)
    md_img_pattern = r"!\[([^\]]*)\]\(([^)]+)\)"

    def replace_md_image(match):
        alt_text = match.group(1)
        image_path = match.group(2)

        new_url, _ = process_image_path(image_path, alt_text)
        if new_url:
            return f"![{alt_text}]({new_url})"
        return match.group(0)

    # 2. å¤„ç† HTML img æ ‡ç­¾ï¼š<img src="path" ...>
    html_img_pattern = r'<img\s+([^>]*\s+)?src="([^"]+)"([^>]*)>'

    def replace_html_image(match):
        before_src = match.group(1) or ""
        image_path = match.group(2)
        after_src = match.group(3) or ""

        # å°è¯•æå– alt å±æ€§
        alt_match = re.search(r'alt="([^"]*)"', before_src + after_src)
        alt_text = alt_match.group(1) if alt_match else "Image"

        new_url, format_type = process_image_path(image_path, alt_text)
        if new_url:
            # ä¿æŒ HTML æ ¼å¼
            return f'<img {before_src}src="{new_url}"{after_src}>'
        return match.group(0)

    try:
        # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡å¼•ç”¨
        new_content = re.sub(md_img_pattern, replace_md_image, md_content)
        new_content = re.sub(html_img_pattern, replace_html_image, new_content)
        return new_content
    except Exception as e:
        logger.error(f"âŒ Failed to process images: {e}")
        return md_content


@app.get("/", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "service": "MinerU Tianshu",
        "version": "1.0.0",
        "description": "å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°",
        "features": "æ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†",
        "docs": "/docs",
    }


@app.post("/api/v1/tasks/submit", tags=["ä»»åŠ¡ç®¡ç†"])
async def submit_task(
    file: UploadFile = File(..., description="æ–‡ä»¶: PDF/å›¾ç‰‡/Office/HTML/éŸ³é¢‘/è§†é¢‘ç­‰å¤šç§æ ¼å¼"),
    backend: str = Form(
        "auto",
        description="å¤„ç†åç«¯: auto (è‡ªåŠ¨é€‰æ‹©) | pipeline/paddleocr-vl (æ–‡æ¡£) | sensevoice (éŸ³é¢‘) | video (è§†é¢‘) | fasta/genbank (ä¸“ä¸šæ ¼å¼)",
    ),
    lang: str = Form("auto", description="è¯­è¨€: auto/ch/en/korean/japanç­‰"),
    method: str = Form("auto", description="è§£ææ–¹æ³•: auto/txt/ocr"),
    formula_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«"),
    table_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«"),
    priority: int = Form(0, description="ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆ"),
    # è§†é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    keep_audio: bool = Form(False, description="è§†é¢‘å¤„ç†æ—¶æ˜¯å¦ä¿ç•™æå–çš„éŸ³é¢‘æ–‡ä»¶"),
    enable_keyframe_ocr: bool = Form(False, description="æ˜¯å¦å¯ç”¨è§†é¢‘å…³é”®å¸§OCRè¯†åˆ«ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰"),
    ocr_backend: str = Form("paddleocr-vl", description="å…³é”®å¸§OCRå¼•æ“: paddleocr-vl"),
    keep_keyframes: bool = Form(False, description="æ˜¯å¦ä¿ç•™æå–çš„å…³é”®å¸§å›¾åƒ"),
    # æ°´å°å»é™¤ä¸“ç”¨å‚æ•°
    remove_watermark: bool = Form(False, description="æ˜¯å¦å¯ç”¨æ°´å°å»é™¤ï¼ˆæ”¯æŒ PDF/å›¾ç‰‡ï¼‰"),
    watermark_conf_threshold: float = Form(0.35, description="æ°´å°æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œæ¨è 0.35ï¼‰"),
    watermark_dilation: int = Form(10, description="æ°´å°æ©ç è†¨èƒ€å¤§å°ï¼ˆåƒç´ ï¼Œæ¨è 10ï¼‰"),
    # [æ–°å¢] PaddleOCR-VL ä¸“ç”¨å‚æ•°
    use_doc_orientation_classify: bool = Form(False, description="[PaddleOCR] å¯ç”¨æ–‡æ¡£æ–¹å‘çŸ«æ­£ (é’ˆå¯¹æ—‹è½¬æ–‡æ¡£)"),
    use_doc_unwarping: bool = Form(False, description="[PaddleOCR] å¯ç”¨æ–‡æ¡£æ‰­æ›²çŸ«æ­£ (é’ˆå¯¹å¼¯æ›²/æŠ˜ç—•æ–‡æ¡£)"),
    use_seal_recognition: bool = Form(False, description="[PaddleOCR] å¯ç”¨å°ç« è¯†åˆ«"),
    use_chart_recognition: bool = Form(False, description="[PaddleOCR] å¯ç”¨å›¾è¡¨è¯†åˆ«"),
    use_ocr_for_image_block: bool = Form(False, description="[PaddleOCR] æ˜¯å¦å¯¹å›¾ç‰‡å—è¿›è¡ŒOCR"),
    merge_tables: bool = Form(True, description="[PaddleOCR] åˆå¹¶è·¨é¡µè¡¨æ ¼"),
    relevel_titles: bool = Form(True, description="[PaddleOCR] æ™ºèƒ½è¯†åˆ«æ ‡é¢˜å±‚çº§"),
    layout_shape_mode: str = Form("auto", description="[PaddleOCR] æ£€æµ‹æ¡†å½¢çŠ¶: auto/rect/quad/poly"),
    # è®¤è¯ä¾èµ–
    current_user: User = Depends(require_permission(Permission.TASK_SUBMIT)),
):
    """
    æäº¤æ–‡æ¡£è§£æä»»åŠ¡

    éœ€è¦è®¤è¯å’Œ TASK_SUBMIT æƒé™ã€‚
    ç«‹å³è¿”å› task_idï¼Œä»»åŠ¡åœ¨åå°å¼‚æ­¥å¤„ç†ã€‚
    """
    try:
        # åˆ›å»ºå…±äº«çš„ä¸Šä¼ ç›®å½•ï¼ˆBackend å’Œ Worker éƒ½èƒ½è®¿é—®ï¼‰
        upload_dir = Path("/app/uploads")
        upload_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆé¿å…å†²çªï¼‰
        unique_filename = f"{uuid.uuid4().hex}_{file.filename}"
        temp_file_path = upload_dir / unique_filename

        # æµå¼å†™å…¥æ–‡ä»¶åˆ°ç£ç›˜ï¼Œé¿å…é«˜å†…å­˜ä½¿ç”¨
        with open(temp_file_path, "wb") as temp_file:
            while True:
                chunk = await file.read(1 << 23)  # 8MB chunks
                if not chunk:
                    break
                temp_file.write(chunk)

        # åˆ›å»ºä»»åŠ¡ (å…³è”ç”¨æˆ·)
        task_id = db.create_task(
            file_name=file.filename,
            file_path=str(temp_file_path),
            backend=backend,
            options={
                "lang": lang,
                "method": method,
                "formula_enable": formula_enable,
                "table_enable": table_enable,
                # è§†é¢‘å¤„ç†å‚æ•°
                "keep_audio": keep_audio,
                "enable_keyframe_ocr": enable_keyframe_ocr,
                "ocr_backend": ocr_backend,
                "keep_keyframes": keep_keyframes,
                # æ°´å°å»é™¤å‚æ•°
                "remove_watermark": remove_watermark,
                "watermark_conf_threshold": watermark_conf_threshold,
                "watermark_dilation": watermark_dilation,
                # [æ–°å¢] PaddleOCR-VL å‚æ•°
                "use_doc_orientation_classify": use_doc_orientation_classify,
                "use_doc_unwarping": use_doc_unwarping,
                "use_seal_recognition": use_seal_recognition,
                "use_chart_recognition": use_chart_recognition,
                "use_ocr_for_image_block": use_ocr_for_image_block,
                "merge_tables": merge_tables,
                "relevel_titles": relevel_titles,
                "layout_shape_mode": layout_shape_mode,
            },
            priority=priority,
            user_id=current_user.user_id,  # å…³è”ç”¨æˆ·
        )

        logger.info(f"âœ… Task submitted: {task_id} - {file.filename}")
        logger.info(f"   User: {current_user.username} ({current_user.role.value})")
        logger.info(f"   Backend: {backend}")
        logger.info(f"   Priority: {priority}")

        return {
            "success": True,
            "task_id": task_id,
            "status": "pending",
            "message": "Task submitted successfully",
            "file_name": file.filename,
            "user_id": current_user.user_id,
            "created_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"âŒ Failed to submit task: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/tasks/{task_id}", tags=["ä»»åŠ¡ç®¡ç†"])
async def get_task_status(
    task_id: str,
    upload_images: bool = Query(False, description="æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ°MinIOå¹¶æ›¿æ¢é“¾æ¥ï¼ˆä»…å½“ä»»åŠ¡å®Œæˆæ—¶æœ‰æ•ˆï¼‰"),
    format: str = Query("markdown", description="è¿”å›æ ¼å¼: markdown(é»˜è®¤)/json/both"),
    current_user: User = Depends(get_current_active_user),
):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œè¯¦æƒ…

    éœ€è¦è®¤è¯ã€‚ç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡ã€‚
    å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä¼šè‡ªåŠ¨è¿”å›è§£æåçš„å†…å®¹ï¼ˆdata å­—æ®µï¼‰
    - format=markdown: åªè¿”å› Markdown å†…å®¹ï¼ˆé»˜è®¤ï¼‰
    - format=json: åªè¿”å› JSON ç»“æ„åŒ–æ•°æ®ï¼ˆMinerU å’Œ PaddleOCR-VL æ”¯æŒï¼‰
    - format=both: åŒæ—¶è¿”å› Markdown å’Œ JSON
    å¯é€‰æ‹©æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢ä¸º URL
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥: ç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜/ç»ç†å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
    if not current_user.has_permission(Permission.TASK_VIEW_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only view your own tasks")

    response = {
        "success": True,
        "task_id": task_id,
        "status": task["status"],
        "file_name": task["file_name"],
        "backend": task["backend"],
        "priority": task["priority"],
        "error_message": task["error_message"],
        "created_at": task["created_at"],
        "started_at": task["started_at"],
        "completed_at": task["completed_at"],
        "worker_id": task["worker_id"],
        "retry_count": task["retry_count"],
        "user_id": task.get("user_id"),
    }
    logger.info(f"âœ… Task status: {task['status']} - (result_path: {task['result_path']})")

    # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œå°è¯•è¿”å›è§£æå†…å®¹
    if task["status"] == "completed":
        if not task["result_path"]:
            # ç»“æœæ–‡ä»¶å·²è¢«æ¸…ç†
            response["data"] = None
            response["message"] = "Task completed but result files have been cleaned up (older than retention period)"
            return response

        result_dir = Path(task["result_path"])
        logger.info(f"ğŸ“‚ Checking result directory: {result_dir}")

        if result_dir.exists():
            logger.info("âœ… Result directory exists")
            # é€’å½’æŸ¥æ‰¾ Markdown æ–‡ä»¶ï¼ˆMinerU è¾“å‡ºç»“æ„ï¼štask_id/filename/auto/*.mdï¼‰
            md_files = list(result_dir.rglob("*.md"))
            # é€’å½’æŸ¥æ‰¾ JSON æ–‡ä»¶
            # MinerU è¾“å‡ºæ ¼å¼: {filename}_content_list.json (ä¸»è¦çš„ç»“æ„åŒ–å†…å®¹)
            # ä¹Ÿæ”¯æŒå…¶ä»–å¼•æ“çš„: content.json, result.json
            json_files = [
                f
                for f in result_dir.rglob("*.json")
                if not f.parent.name.startswith("page_")
                and (f.name in ["content.json", "result.json"] or "_content_list.json" in f.name)
            ]
            logger.info(f"ğŸ“„ Found {len(md_files)} markdown files and {len(json_files)} json files")

            if md_files:
                try:
                    # åˆå§‹åŒ– data å­—æ®µ
                    response["data"] = {}

                    # æ ‡è®° JSON æ˜¯å¦å¯ç”¨
                    response["data"]["json_available"] = len(json_files) > 0

                    # æ ¹æ® format å‚æ•°å†³å®šè¿”å›å†…å®¹
                    if format in ["markdown", "both"]:
                        # é€‰æ‹©ä¸» Markdown æ–‡ä»¶ï¼ˆä¼˜å…ˆ result.mdï¼‰
                        md_file = None
                        for f in md_files:
                            if f.name == "result.md":
                                md_file = f
                                break
                        if not md_file:
                            md_file = md_files[0]

                        # æŸ¥æ‰¾å›¾ç‰‡ç›®å½•ï¼ˆWorker å·²è§„èŒƒåŒ–ä¸º images/ï¼‰
                        image_dir = md_file.parent / "images"

                        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
                        cached_md_file = md_file.parent / "result_minio.md" if upload_images else None

                        # å¦‚æœè¯·æ±‚ MinIO ç‰ˆæœ¬ä¸”ç¼“å­˜å­˜åœ¨ï¼Œç›´æ¥è¿”å›ç¼“å­˜
                        if upload_images and cached_md_file and cached_md_file.exists():
                            logger.info(f"âœ… Found cached MinIO markdown: {cached_md_file.name}")
                            with open(cached_md_file, "r", encoding="utf-8") as f:
                                md_content = f.read()

                            response["data"]["markdown_file"] = cached_md_file.name
                            response["data"]["content"] = md_content
                            response["data"]["images_uploaded"] = True
                            response["data"]["from_cache"] = True
                        else:
                            # è¯»å–åŸå§‹ Markdown å†…å®¹
                            logger.info(f"ğŸ“– Reading markdown file: {md_file}")
                            with open(md_file, "r", encoding="utf-8") as f:
                                md_content = f.read()

                            logger.info(f"âœ… Markdown content loaded, length: {len(md_content)} characters")

                            # å¤„ç†å›¾ç‰‡è·¯å¾„
                            if image_dir.exists():
                                logger.info(f"ğŸ–¼ï¸  Processing images for task {task_id}, upload_images={upload_images}")
                                logger.info(f"   Image directory: {image_dir}")
                                md_content = process_markdown_images(
                                    md_content, image_dir, task["result_path"], upload_images
                                )

                                # å¦‚æœä¸Šä¼ åˆ° MinIOï¼Œä¿å­˜ç¼“å­˜æ–‡ä»¶
                                if upload_images and cached_md_file:
                                    try:
                                        cached_md_file.write_text(md_content, encoding="utf-8")
                                        logger.info(f"ğŸ’¾ Saved MinIO markdown cache: {cached_md_file.name}")
                                    except Exception as e:
                                        logger.warning(f"âš ï¸  Failed to save cache: {e}")
                            else:
                                logger.debug("â„¹ï¸  No images directory found (task may not contain images)")

                            # æ·»åŠ  Markdown ç›¸å…³å­—æ®µ
                            response["data"]["markdown_file"] = md_file.name
                            response["data"]["content"] = md_content
                            response["data"]["images_uploaded"] = upload_images
                            response["data"]["has_images"] = image_dir.exists() if not upload_images else None
                            response["data"]["from_cache"] = False

                    # å¦‚æœç”¨æˆ·è¯·æ±‚ JSON æ ¼å¼
                    if format in ["json", "both"] and json_files:
                        import json as json_lib

                        json_file = json_files[0]
                        logger.info(f"ğŸ“– Reading JSON file: {json_file}")
                        try:
                            with open(json_file, "r", encoding="utf-8") as f:
                                json_content = json_lib.load(f)
                            response["data"]["json_file"] = json_file.name
                            response["data"]["json_content"] = json_content
                            logger.info("âœ… JSON content loaded successfully")
                        except Exception as json_e:
                            logger.warning(f"âš ï¸  Failed to load JSON: {json_e}")
                    elif format == "json" and not json_files:
                        # ç”¨æˆ·è¯·æ±‚ JSON ä½†æ²¡æœ‰ JSON æ–‡ä»¶
                        logger.warning("âš ï¸  JSON format requested but no JSON file available")
                        response["data"]["message"] = "JSON format not available for this backend"

                    # å¦‚æœæ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹ï¼Œæ·»åŠ æç¤º
                    if not response["data"]:
                        response["data"] = None
                        logger.warning(f"âš ï¸  No data returned for format: {format}")
                    else:
                        logger.info(f"âœ… Response data field added successfully (format={format})")

                except Exception as e:
                    logger.error(f"âŒ Failed to read content: {e}")
                    logger.exception(e)
                    # è¯»å–å¤±è´¥ä¸å½±å“çŠ¶æ€æŸ¥è¯¢ï¼Œåªæ˜¯ä¸è¿”å› data
                    response["data"] = None
            else:
                logger.warning(f"âš ï¸  No markdown files found in {result_dir}")
        else:
            logger.error(f"âŒ Result directory does not exist: {result_dir}")
    elif task["status"] == "completed":
        logger.warning("âš ï¸  Task completed but result_path is empty")
    else:
        logger.info(f"â„¹ï¸  Task status is {task['status']}, skipping content loading")

    return response


@app.delete("/api/v1/tasks/{task_id}", tags=["ä»»åŠ¡ç®¡ç†"])
async def cancel_task(task_id: str, current_user: User = Depends(get_current_active_user)):
    """
    å–æ¶ˆä»»åŠ¡ï¼ˆä»…é™ pending çŠ¶æ€ï¼‰

    éœ€è¦è®¤è¯ã€‚ç”¨æˆ·åªèƒ½å–æ¶ˆè‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥å–æ¶ˆä»»ä½•ä»»åŠ¡ã€‚
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥: ç”¨æˆ·åªèƒ½å–æ¶ˆè‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥å–æ¶ˆä»»ä½•ä»»åŠ¡
    if not current_user.has_permission(Permission.TASK_DELETE_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only cancel your own tasks")

    if task["status"] == "pending":
        db.update_task_status(task_id, "cancelled")

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        file_path = Path(task["file_path"])
        if file_path.exists():
            file_path.unlink()

        logger.info(f"â¹ï¸  Task cancelled: {task_id} by user {current_user.username}")
        return {"success": True, "message": "Task cancelled successfully"}
    else:
        raise HTTPException(status_code=400, detail=f"Cannot cancel task in {task['status']} status")


@app.get("/api/v1/queue/stats", tags=["é˜Ÿåˆ—ç®¡ç†"])
async def get_queue_stats(current_user: User = Depends(require_permission(Permission.QUEUE_VIEW))):
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯

    éœ€è¦è®¤è¯å’Œ QUEUE_VIEW æƒé™ã€‚
    """
    stats = db.get_queue_stats()

    return {
        "success": True,
        "stats": stats,
        "total": sum(stats.values()),
        "timestamp": datetime.now().isoformat(),
        "user": current_user.username,
    }


@app.get("/api/v1/queue/tasks", tags=["é˜Ÿåˆ—ç®¡ç†"])
async def list_tasks(
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€: pending/processing/completed/failed"),
    limit: int = Query(100, description="è¿”å›æ•°é‡é™åˆ¶", le=1000),
    current_user: User = Depends(get_current_active_user),
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨

    éœ€è¦è®¤è¯ã€‚æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜/ç»ç†å¯ä»¥çœ‹åˆ°æ‰€æœ‰ä»»åŠ¡ã€‚
    """
    # æ£€æŸ¥ç”¨æˆ·æƒé™
    can_view_all = current_user.has_permission(Permission.TASK_VIEW_ALL)

    if can_view_all:
        # ç®¡ç†å‘˜/ç»ç†æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
        if status:
            tasks = db.get_tasks_by_status(status, limit)
        else:
            with db.get_cursor() as cursor:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (limit,),
                )
                tasks = [dict(row) for row in cursor.fetchall()]
    else:
        # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡
        with db.get_cursor() as cursor:
            if status:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE user_id = ? AND status = ?
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (current_user.user_id, status, limit),
                )
            else:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE user_id = ?
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (current_user.user_id, limit),
                )
            tasks = [dict(row) for row in cursor.fetchall()]

    return {"success": True, "count": len(tasks), "tasks": tasks, "can_view_all": can_view_all}


@app.post("/api/v1/admin/cleanup", tags=["ç³»ç»Ÿç®¡ç†"])
async def cleanup_old_tasks(
    days: int = Query(7, description="æ¸…ç†Nå¤©å‰çš„ä»»åŠ¡"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    æ¸…ç†æ—§ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰

    åŒæ—¶åˆ é™¤ä»»åŠ¡çš„æ‰€æœ‰ç›¸å…³æ–‡ä»¶å’Œæ•°æ®åº“è®°å½•ï¼š
    - ä¸Šä¼ çš„åŸå§‹æ–‡ä»¶
    - ç»“æœæ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬ç”Ÿæˆçš„æ–‡ä»¶å’Œæ‰€æœ‰ä¸­é—´æ–‡ä»¶ï¼‰
    - æ•°æ®åº“è®°å½•

    éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚
    """
    deleted_count = db.cleanup_old_task_records(days)

    logger.info(f"ğŸ§¹ Cleaned up {deleted_count} old tasks (files and records) by {current_user.username}")

    return {
        "success": True,
        "deleted_count": deleted_count,
        "message": f"Cleaned up {deleted_count} tasks older than {days} days (files and records deleted)",
    }


@app.post("/api/v1/admin/reset-stale", tags=["ç³»ç»Ÿç®¡ç†"])
async def reset_stale_tasks(
    timeout_minutes: int = Query(60, description="è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    é‡ç½®è¶…æ—¶çš„ processing ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰

    éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚
    """
    reset_count = db.reset_stale_tasks(timeout_minutes)

    logger.info(f"ğŸ”„ Reset {reset_count} stale tasks by {current_user.username}")

    return {
        "success": True,
        "reset_count": reset_count,
        "message": f"Reset tasks processing for more than {timeout_minutes} minutes",
    }


@app.get("/api/v1/engines", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def list_engines():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“

    æ— éœ€è®¤è¯ã€‚è¿”å›ç³»ç»Ÿä¸­æ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“ä¿¡æ¯ã€‚
    """
    engines = {
        "document": [
            {
                "name": "pipeline",
                "display_name": "MinerU Pipeline",
                "description": "é»˜è®¤çš„ PDF/å›¾ç‰‡è§£æå¼•æ“ï¼Œæ”¯æŒå…¬å¼ã€è¡¨æ ¼ç­‰å¤æ‚ç»“æ„",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            },
        ],
        "ocr": [],
        "audio": [],
        "video": [],
        "format": [],
        "office": [
            {
                "name": "markitdown",
                "display_name": "MarkItDown",
                "description": "Office æ–‡æ¡£å’Œæ–‡æœ¬æ–‡ä»¶è½¬æ¢å¼•æ“",
                "supported_formats": [".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt", ".html", ".txt", ".csv"],
            },
        ],
    }

    # åŠ¨æ€æ£€æµ‹å¯ç”¨å¼•æ“
    import importlib.util

    if importlib.util.find_spec("paddleocr_vl") is not None:
        engines["ocr"].append(
            {
                "name": "paddleocr_vl",
                "display_name": "PaddleOCR-VL",
                "description": "PaddlePaddle è§†è§‰è¯­è¨€ OCR å¼•æ“",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            }
        )

    if importlib.util.find_spec("paddleocr_vl_vllm") is not None:
        engines["ocr"].append(
            {
                "name": "paddleocr-vl-vllm",
                "display_name": "PaddleOCR-VL-VLLM",
                "description": "åŸºäº vLLM çš„é«˜æ€§èƒ½ PaddleOCR å¼•æ“",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            }
        )

    if importlib.util.find_spec("audio_engines") is not None:
        engines["audio"].append(
            {
                "name": "sensevoice",
                "display_name": "SenseVoice",
                "description": "è¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œæ”¯æŒå¤šè¯­è¨€è‡ªåŠ¨æ£€æµ‹",
                "supported_formats": [".wav", ".mp3", ".flac", ".m4a", ".ogg"],
            }
        )

    if importlib.util.find_spec("video_engines") is not None:
        engines["video"].append(
            {
                "name": "video",
                "display_name": "Video Processing",
                "description": "è§†é¢‘å¤„ç†å¼•æ“ï¼Œæ”¯æŒå…³é”®å¸§æå–å’ŒéŸ³é¢‘è½¬å½•",
                "supported_formats": [".mp4", ".avi", ".mkv", ".mov", ".flv", ".wmv"],
            }
        )

    # ä¸“ä¸šæ ¼å¼å¼•æ“
    try:
        from format_engines import FormatEngineRegistry

        for engine_info in FormatEngineRegistry.list_engines():
            engines["format"].append(
                {
                    "name": engine_info["name"],
                    "display_name": engine_info["name"].upper(),
                    "description": engine_info["description"],
                    "supported_formats": engine_info["extensions"],
                }
            )
    except ImportError:
        pass

    return {
        "success": True,
        "engines": engines,
        "timestamp": datetime.now().isoformat(),
    }


@app.get("/api/v1/health", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        stats = db.get_queue_stats()

        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": "connected",
            "queue_stats": stats,
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(status_code=503, content={"status": "unhealthy", "error": str(e)})


# ============================================================================
# è‡ªå®šä¹‰æ–‡ä»¶æœåŠ¡ï¼ˆæ”¯æŒ URL ç¼–ç çš„ä¸­æ–‡è·¯å¾„ï¼‰
# ============================================================================
from urllib.parse import unquote


@app.get("/v1/files/output/{file_path:path}", tags=["æ–‡ä»¶æœåŠ¡"])
async def serve_output_file(file_path: str):
    """
    æä¾›è¾“å‡ºæ–‡ä»¶çš„è®¿é—®æœåŠ¡

    æ”¯æŒ URL ç¼–ç çš„ä¸­æ–‡è·¯å¾„
    æ³¨æ„ï¼šNginx ä»£ç†ä¼šå»æ‰ /api/ å‰ç¼€ï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦ /api/
    """
    try:
        logger.debug(f"ğŸ“¥ Received file request: {file_path}")
        # URL è§£ç 
        decoded_path = unquote(file_path)
        logger.debug(f"ğŸ“ Decoded path: {decoded_path}")
        # æ„å»ºå®Œæ•´è·¯å¾„
        full_path = OUTPUT_DIR / decoded_path
        logger.debug(f"ğŸ“‚ Full path: {full_path}")

        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è·¯å¾„åœ¨ OUTPUT_DIR å†…
        try:
            full_path = full_path.resolve()
            OUTPUT_DIR.resolve()
            if not str(full_path).startswith(str(OUTPUT_DIR.resolve())):
                raise HTTPException(status_code=403, detail="Access denied")
        except Exception:
            raise HTTPException(status_code=403, detail="Invalid path")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not full_path.exists():
            logger.warning(f"âš ï¸  File not found: {full_path}")
            raise HTTPException(status_code=404, detail="File not found")

        if not full_path.is_file():
            raise HTTPException(status_code=404, detail="Not a file")

        # è¿”å›æ–‡ä»¶
        return FileResponse(path=str(full_path), media_type="application/octet-stream", filename=full_path.name)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Error serving file: {e}")
        raise HTTPException(status_code=500, detail=str(e))


logger.info(f"ğŸ“ File service mounted: /v1/files/output -> {OUTPUT_DIR}")
logger.info("   Frontend can access images via: /api/v1/files/output/{task_id}/images/xxx.jpg (Nginx will strip /api/)")


if __name__ == "__main__":
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç«¯å£ï¼Œé»˜è®¤ä¸º8000
    api_port = int(os.getenv("API_PORT", "8000"))

    logger.info("ğŸš€ Starting MinerU Tianshu API Server...")
    logger.info(f"ğŸ“– API Documentation: http://localhost:{api_port}/docs")

    uvicorn.run(app, host="0.0.0.0", port=api_port, log_level="info")
