"""
PaddleOCR-VL-VLLM è§£æå¼•æ“ (å…¨åŠŸèƒ½ç‰ˆ)
å•ä¾‹æ¨¡å¼ï¼Œæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡åŸºç¡€ç‰ˆé¢è¯†åˆ«æ¨¡å‹,OCRéƒ¨åˆ†è°ƒç”¨é…ç½®çš„API
ä½¿ç”¨æœ€æ–°çš„ PaddleOCR-VL-VLLM APIï¼ˆè‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼‰

å‚è€ƒæ–‡æ¡£ï¼šhttps://www.paddleocr.ai/latest/version3.x/pipeline_usage/PaddleOCR-VL.html#322-python-api
"""

from pathlib import Path
from typing import Optional, Dict, Any
from threading import Lock
from loguru import logger
import json
import os


class PaddleOCRVLVLLMEngine:
    """
    PaddleOCR-VL-VLLM è§£æå¼•æ“ï¼ˆæ–°ç‰ˆæœ¬ï¼‰

    ç‰¹æ€§ï¼š
    - å•ä¾‹æ¨¡å¼ï¼ˆæ¯ä¸ªè¿›ç¨‹åªåŠ è½½ä¸€æ¬¡æ¨¡å‹ï¼‰
    - è‡ªåŠ¨å¤šè¯­è¨€è¯†åˆ«ï¼ˆæ— éœ€æŒ‡å®šè¯­è¨€ï¼Œæ”¯æŒ 109+ è¯­è¨€ï¼‰
    - çº¿ç¨‹å®‰å…¨
    - ä»…æ”¯æŒ GPU æ¨ç†ï¼ˆä¸æ”¯æŒ CPUï¼‰
    - åŸç”Ÿæ”¯æŒ PDF å¤šé¡µæ–‡æ¡£è§£æ
    - ç»“æ„åŒ–è¾“å‡ºï¼ˆMarkdown/JSONï¼‰
    - æ¨¡å‹è‡ªåŠ¨ä¸‹è½½å’Œç¼“å­˜ï¼ˆç”± PaddleOCR ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨ä¸‹è½½ï¼‰

    GPU è¦æ±‚ï¼š
    - NVIDIA GPU with Compute Capability â‰¥ 8.5
    - æ¨èï¼šRTX 3090, RTX 4090, A10, A100, H100
    """

    _instance: Optional["PaddleOCRVLVLLMEngine"] = None
    _lock = Lock()
    _pipeline = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, device: str = "cuda:0", vllm_api_base: str = "http://localhost:17300/v1"):
        """
        åˆå§‹åŒ–å¼•æ“ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰

        Args:
            device: è®¾å¤‡ (cuda:0, cuda:1 ç­‰ï¼ŒPaddleOCR ä»…æ”¯æŒ GPU)
            vllm_api_base: VLLM API åŸºç¡€ URL (é»˜è®¤: http://localhost:17300/v1)
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.device = device  # ä¿å­˜ device å‚æ•°
            self.vllm_api_base = vllm_api_base  # ä¿å­˜ vllm_api_base å‚æ•°

            # ä» device å­—ç¬¦ä¸²ä¸­æå– GPU ID (ä¾‹å¦‚ "cuda:0" -> 0)
            if "cuda:" in device:
                self.gpu_id = int(device.split(":")[-1])
            else:
                self.gpu_id = 0
                logger.warning(f"âš ï¸  Invalid device format: {device}, using GPU 0")

            # æ£€æŸ¥ GPU å¯ç”¨æ€§ï¼ˆPaddleOCR-VL ä»…æ”¯æŒ GPUï¼‰
            self._check_gpu_availability()

            self._initialized = True

            logger.info("ğŸ”§ PaddleOCR-VL-VLLM Engine initialized")
            logger.info(f"   Device: {self.device} (GPU ID: {self.gpu_id})")
            logger.info(f"   VLLM API Base: {self.vllm_api_base}")
            logger.info("   Model: PaddlePaddle/PaddleOCR-VL (auto-managed)")
            logger.info("   Auto Multi-Language: Enabled (109+ languages)")
            logger.info("   GPU Only: CPU not supported")
            logger.info("   Model Cache: ~/.paddleocr/models/ (auto-managed)")

    def _check_gpu_availability(self):
        """
        æ£€æŸ¥ GPU ä¿¡æ¯å¹¶è¾“å‡ºæ—¥å¿—
        PaddleOCR-VL ä»…æ”¯æŒ GPU æ¨ç†ï¼Œä½†ä¸é˜»æ­¢ä½ç‰ˆæœ¬ GPU è¿è¡Œ
        """
        try:
            import paddle

            # æ£€æŸ¥æ˜¯å¦ç¼–è¯‘äº† CUDA æ”¯æŒ
            if not paddle.is_compiled_with_cuda():
                logger.warning("âš ï¸  PaddlePaddle is not compiled with CUDA")
                logger.warning("   PaddleOCR-VL requires GPU support")
                logger.warning("   Install: pip install paddlepaddle-gpu==3.2.0")
                return

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count == 0:
                logger.warning("âš ï¸  No CUDA devices found")
                logger.warning("   PaddleOCR-VL requires GPU for inference")
                return

            # è·å– GPU ä¿¡æ¯
            try:
                gpu_name = paddle.device.cuda.get_device_name(0)
                compute_capability = paddle.device.cuda.get_device_capability(0)

                logger.info(f"âœ… GPU detected: {gpu_name}")
                logger.info(f"   Compute Capability: {compute_capability[0]}.{compute_capability[1]}")
                logger.info(f"   GPU Count: {gpu_count}")

                # ä»…è¾“å‡ºå»ºè®®ï¼Œä¸é˜»æ­¢è¿è¡Œ
                cc_major = compute_capability[0]
                cc_minor = compute_capability[1]
                if cc_major < 8 or (cc_major == 8 and cc_minor < 5):
                    logger.info("â„¹ï¸  GPU Compute Capability < 8.5")
                    logger.info("   Official recommendation: CC â‰¥ 8.5 for best performance")
                    logger.info("   Your GPU may still work, but performance might vary")
            except Exception as e:
                logger.debug(f"Could not get detailed GPU info: {e}")

        except ImportError:
            logger.warning("âš ï¸  PaddlePaddle not installed")
            logger.warning("   Install: pip install paddlepaddle-gpu==3.2.0")
        except Exception as e:
            logger.debug(f"GPU check warning: {e}")

    def _load_pipeline(self):
        """å»¶è¿ŸåŠ è½½ PaddleOCR-VL-VLLM ç®¡é“"""
        if self._pipeline is not None:
            return self._pipeline

        with self._lock:
            if self._pipeline is not None:
                return self._pipeline

            logger.info("=" * 60)
            logger.info("ğŸ“¥ Loading PaddleOCR-VL-VLLM Pipeline into memory...")
            logger.info("=" * 60)

            try:
                import paddle
                from paddleocr import PaddleOCRVL

                # è®¾ç½® PaddlePaddle ä½¿ç”¨æŒ‡å®šçš„ GPU
                # å¿…é¡»åœ¨åˆ›å»º PaddleOCRVL å®ä¾‹ä¹‹å‰è®¾ç½®
                if paddle.is_compiled_with_cuda():
                    paddle.set_device(f"gpu:{self.gpu_id}")
                    logger.info(f"ğŸ¯ PaddlePaddle device set to: gpu:{self.gpu_id}")
                else:
                    logger.warning("âš ï¸  CUDA not available, PaddleOCR-VL may not work")

                # åˆå§‹åŒ– PaddleOCR-VLï¼ˆæ–°ç‰ˆæœ¬ APIï¼‰
                logger.info("ğŸ¤– Initializing PaddleOCR-VL-VLLM Pipeline...")
                
                if self.vllm_api_base is None:
                    raise ValueError(
                        "vllm_api_base ä¸èƒ½ä¸º Noneï¼Œè¯·æ£€æŸ¥paddleocr-vl-vllm-engine-enabled åŠ paddleocr-vl-vllm-api-list é…ç½®"
                    )
                else:
                    # åˆå§‹åŒ– pipeline
                    # æ³¨æ„ï¼šè¿™é‡Œä»…åšåŸºç¡€åˆå§‹åŒ–ï¼Œå…·ä½“çš„åŠŸèƒ½å¼€å…³ï¼ˆå¦‚å°ç« ã€çŸ«æ­£ï¼‰åœ¨ predict æ—¶é€šè¿‡å‚æ•°æ§åˆ¶
                    self._pipeline = PaddleOCRVL(
                        vl_rec_backend="vllm-server",  # ä½¿ç”¨ VLLM åç«¯
                        vl_rec_server_url=self.vllm_api_base,  # VLLM æœåŠ¡å™¨åœ°å€
                        use_layout_detection=True  # é»˜è®¤å¼€å¯åŸºç¡€ç‰ˆé¢åˆ†æ
                    )

                logger.info("=" * 60)
                logger.info("âœ… PaddleOCR-VL-VLLM Pipeline loaded successfully!")
                logger.info(f"   Device: GPU {self.gpu_id}")
                logger.info("   Backend: VLLM Server")
                logger.info("=" * 60)

                return self._pipeline

            except Exception as e:
                logger.error("=" * 80)
                logger.error("âŒ ç®¡é“åŠ è½½å¤±è´¥:")
                logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
                logger.error("=" * 80)

                import traceback
                logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
                logger.debug(traceback.format_exc())
                raise

    def cleanup(self):
        """
        æ¸…ç†æ¨ç†äº§ç”Ÿçš„æ˜¾å­˜ï¼ˆä¸å¸è½½æ¨¡å‹ï¼‰
        """
        try:
            import paddle
            import gc

            # æ¸…ç† PaddlePaddle æ˜¾å­˜
            if paddle.device.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
                logger.debug("ğŸ§¹ PaddleOCR-VL-VLLM: CUDA cache cleared")

            # æ¸…ç† Python å¯¹è±¡
            gc.collect()

            logger.debug("ğŸ§¹ PaddleOCR-VL-VLLM: Memory cleanup completed")
        except Exception as e:
            logger.debug(f"Memory cleanup warning: {e}")

    def parse(self, file_path: str, output_path: str, **kwargs) -> Dict[str, Any]:
        """
        å…¨åŠŸèƒ½è§£æå…¥å£ï¼šè§£ææ–‡æ¡£æˆ–å›¾ç‰‡

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            **kwargs: åŠ¨æ€æ¥æ”¶å®˜ç½‘æ”¯æŒçš„æ‰€æœ‰é«˜çº§å‚æ•°ï¼Œä¾‹å¦‚ï¼š
                - use_doc_orientation_classify (bool): å›¾ç‰‡æ–¹å‘çŸ«æ­£
                - use_doc_unwarping (bool): å›¾ç‰‡æ‰­æ›²çŸ«æ­£
                - use_seal_recognition (bool): å°ç« è¯†åˆ«
                - use_chart_recognition (bool): å›¾è¡¨è¯†åˆ«
                - use_ocr_for_image_block (bool): å›¾ç‰‡æ–‡å­—è¯†åˆ«
                - merge_tables (bool): è·¨é¡µè¡¨æ ¼åˆå¹¶ (åå¤„ç†)
                - relevel_titles (bool): æ®µè½æ ‡é¢˜çº§åˆ«è¯†åˆ« (åå¤„ç†)
                - markdown_ignore_labels (list): è¾…åŠ©å†…å®¹è¿‡æ»¤ (å¦‚é¡µçœ‰é¡µè„š)
                - layout_shape_mode (str): ç‰ˆé¢å½¢çŠ¶ (auto/rect/quad/poly)
                - min_pixels, max_pixels (int): å›¾åƒåƒç´ é™åˆ¶
                - repetition_penalty, temperature, top_p (float): VLLM ç”Ÿæˆå‚æ•°

        Returns:
            è§£æç»“æœï¼ˆåŒæ—¶ä¿å­˜ Markdown å’Œ JSON ä¸¤ç§æ ¼å¼ï¼‰
        """
        file_path = Path(file_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ¤– PaddleOCR-VL-VLLM parsing: {file_path.name}")
        
        # åŠ è½½ç®¡é“
        pipeline = self._load_pipeline()

        # 1. æ„é€  predict å‚æ•°å­—å…¸
        # ä½¿ç”¨ kwargs.get() è®¾ç½®é»˜è®¤å€¼ï¼Œç¡®ä¿ä¸å®˜ç½‘ API é»˜è®¤è¡Œä¸ºä¸€è‡´
        predict_params = {
            "input": str(file_path),
            
            # --- å›¾åƒçŸ«æ­£ & é¢„å¤„ç† ---
            "use_doc_orientation_classify": kwargs.get("use_doc_orientation_classify", False),
            "use_doc_unwarping": kwargs.get("use_doc_unwarping", False),
            "min_pixels": kwargs.get("min_pixels", 147384),
            "max_pixels": kwargs.get("max_pixels", 2822400),
            
            # --- ç‰ˆé¢åˆ†æ & è¯†åˆ«åŠŸèƒ½ ---
            "use_layout_detection": kwargs.get("use_layout_detection", True),
            "use_chart_recognition": kwargs.get("use_chart_recognition", False),
            "use_seal_recognition": kwargs.get("use_seal_recognition", False),
            "use_ocr_for_image_block": kwargs.get("use_ocr_for_image_block", False),
            
            # --- é«˜çº§è®¾ç½® ---
            "layout_shape_mode": kwargs.get("layout_shape_mode", "auto"), # auto, rect, quad, poly
            "layout_nms": kwargs.get("layout_nms", True),
            "prompt_label": kwargs.get("prompt_label", None), # ä»…å½“ use_layout_detection=False æ—¶ç”Ÿæ•ˆ
            
            # --- VLLM ç”Ÿæˆå‚æ•° ---
            "repetition_penalty": kwargs.get("repetition_penalty", 1.0),
            "temperature": kwargs.get("temperature", 0.0),
            "top_p": kwargs.get("top_p", 1.0),
            
            # --- è¾…åŠ©å†…å®¹è¿‡æ»¤ (Markdownå¿½ç•¥æ ‡ç­¾) ---
            # é»˜è®¤å¿½ç•¥ï¼šé¡µç (number), è„šæ³¨(footnote), é¡µçœ‰(header), é¡µè„š(footer)ç­‰
            "markdown_ignore_labels": kwargs.get("markdown_ignore_labels", [
                'number', 'footnote', 'header', 'header_image', 
                'footer', 'footer_image', 'aside_text'
            ]),
        }
        
        # æ‰“å°å…³é”®å‚æ•°ä»¥ä¾¿è°ƒè¯•
        logger.info(f"âš™ï¸  åŠŸèƒ½å¼€å…³: æ–¹å‘çŸ«æ­£={predict_params['use_doc_orientation_classify']}, "
                    f"æ‰­æ›²çŸ«æ­£={predict_params['use_doc_unwarping']}, "
                    f"å°ç« è¯†åˆ«={predict_params['use_seal_recognition']}")

        # æ‰§è¡Œæ¨ç†
        try:
            # 2. è°ƒç”¨ Pipeline è¿›è¡Œé¢„æµ‹
            result = pipeline.predict(**predict_params)
            logger.info("âœ… æ¨ç†å®Œæˆ")

            # 3. åå¤„ç†ï¼šé¡µé¢é‡æ„ (è·¨é¡µåˆå¹¶ã€æ ‡é¢˜åˆ†çº§)
            # è¿™äº›åŠŸèƒ½æ˜¯é€šè¿‡ restructure_pages å®ç°çš„
            should_restructure = kwargs.get("restructure_pages", True) # é»˜è®¤å¼€å¯
            
            if should_restructure and hasattr(pipeline, "restructure_pages"):
                logger.info("ğŸ”„ æ­£åœ¨æ‰§è¡Œé¡µé¢é‡æ„ (è¡¨æ ¼åˆå¹¶ & æ ‡é¢˜åˆ†çº§)...")
                try:
                    result = pipeline.restructure_pages(
                        result,
                        merge_table=kwargs.get("merge_tables", True),     # è·¨é¡µè¡¨æ ¼åˆå¹¶
                        relevel_titles=kwargs.get("relevel_titles", True) # æ ‡é¢˜çº§åˆ«è¯†åˆ«
                    )
                    logger.info("âœ… é¡µé¢é‡æ„å®Œæˆ")
                except Exception as re_err:
                    logger.warning(f"âš ï¸ é¡µé¢é‡æ„å¤±è´¥ (é™çº§ä½¿ç”¨åŸå§‹ç»“æœ): {re_err}")
                    import traceback
                    logger.debug(traceback.format_exc())

            logger.info(f"   è¯†åˆ«äº† {len(result)} é¡µ/å¼ ")

            # 4. ä¿å­˜ç»“æœ
            markdown_list = []
            json_list = []

            for idx, res in enumerate(result, 1):
                logger.info(f"ğŸ“ å¤„ç†ç»“æœ {idx}/{len(result)}")

                try:
                    # ä¸ºæ¯é¡µåˆ›å»ºå­ç›®å½•å¹¶ä¿å­˜å®Œæ•´ç»“æœï¼ˆä¾¿äºè°ƒè¯•ï¼‰
                    page_output_dir = output_path / f"page_{idx}"
                    page_output_dir.mkdir(parents=True, exist_ok=True)

                    # ä¿å­˜ JSONï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
                    if hasattr(res, "save_to_json"):
                        res.save_to_json(save_path=str(page_output_dir))

                    # ä¿å­˜ Markdown æ–‡ä»¶ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
                    if hasattr(res, "save_to_markdown"):
                        res.save_to_markdown(save_path=str(page_output_dir))

                    # æ”¶é›†ç»“æœç”¨äºåˆå¹¶
                    if hasattr(res, "markdown"):
                        markdown_list.append(res.markdown)
                        logger.info("   âœ… æå–æˆåŠŸ")
                    
                    if hasattr(res, "json"):
                        json_list.append(res.json)

                except Exception as e:
                    logger.warning(f"   å¤„ç†å‡ºé”™: {e}")
                    import traceback
                    logger.debug(traceback.format_exc())

            # ä½¿ç”¨å®˜æ–¹æ–¹æ³•åˆå¹¶æ‰€æœ‰é¡µçš„ Markdown
            if hasattr(pipeline, "concatenate_markdown_pages"):
                markdown_text = pipeline.concatenate_markdown_pages(markdown_list)
                logger.info("   ä½¿ç”¨å®˜æ–¹ concatenate_markdown_pages() æ–¹æ³•åˆå¹¶")
            else:
                # é™çº§æ–¹æ¡ˆï¼šæ‰‹åŠ¨åˆå¹¶
                logger.warning("   æœªæ‰¾åˆ° concatenate_markdown_pages() æ–¹æ³•ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                markdown_text = "\n\n---\n\n".join(
                    [str(md) if isinstance(md, str) else str(md.get("text", "")) for md in markdown_list]
                )

            # ä¿å­˜åˆå¹¶åçš„ Markdown æ–‡ä»¶
            markdown_file = output_path / "result.md"
            markdown_file.write_text(markdown_text, encoding="utf-8")
            logger.info(f"ğŸ“„ Markdown å·²ä¿å­˜: {markdown_file}")
            logger.info(f"   {len(result)} é¡µ | {len(markdown_text):,} å­—ç¬¦")

            # å§‹ç»ˆä¿å­˜ JSON æ–‡ä»¶
            json_file = None
            if json_list:
                json_file = output_path / "result.json"
                # åˆå¹¶æ‰€æœ‰é¡µçš„ JSON
                combined_json = {"pages": json_list, "total_pages": len(result)}
                with open(json_file, "w", encoding="utf-8") as f:
                    json.dump(combined_json, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ“„ JSON å·²ä¿å­˜: {json_file}")
            else:
                logger.warning("âš ï¸  æ— æ³•æå– JSON æ•°æ®")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown": markdown_text,
                "markdown_file": str(markdown_file),
                "json_file": str(json_file) if json_file else None,
                "result": result,
            }

        except Exception as e:
            logger.error("=" * 80)
            logger.error("âŒ OCR è§£æå¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
            logger.error("=" * 80)

            import traceback
            logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
            logger.debug(traceback.format_exc())

            raise

        finally:
            # æ¸…ç†æ˜¾å­˜ï¼ˆæ— è®ºæˆåŠŸæˆ–å¤±è´¥éƒ½æ‰§è¡Œï¼‰
            self.cleanup()


# å…¨å±€å•ä¾‹
_engine = None


def get_engine() -> PaddleOCRVLVLLMEngine:
    """è·å–å…¨å±€å¼•æ“å®ä¾‹"""
    global _engine
    if _engine is None:
        _engine = PaddleOCRVLVLLMEngine()
    return _engine
